---
title: 'Analysis of MH600 panels x cnakepit pipeline (hg37)'
output:
  distill::distill_article:
    theme: hpstr
    toc: yes
    code_folding: true
    keep_md: yes
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, include = TRUE, echo = FALSE)

.packages <- c("tidyverse", "ggpubr", "gplots", "rmarkdown", "this.path", "RColorBrewer")

# Install CRAN packages (if not already installed)
.inst <- .packages %in% installed.packages()
if (length(.packages[!.inst]) > 0) install.packages(.packages[!.inst], dependencies = TRUE, quiet = TRUE, repos = "https://cran.uni-muenster.de/")

# Load packages into session
lapply(.packages, require, character.only = TRUE)

dir <- dirname(this.path()) # Get directory of running file
```

# FASTQ file sizes

```{r read fastq file sizes, echo=FALSE, message=FALSE, warning=FALSE}
read_tsv(paste(dir, "/../resources/data/all_samples_filepath_size.tsv", sep = "")) %>%
  group_by(SampleName) %>%
  arrange(FileSize) %>%
  select(-FilePath) %>%
  mutate(FileName = str_remove(FileName, ".*_S[0-9]+_Lx_")) %>%
  pivot_wider(names_from = FileName, values_from = FileSize) %>%
  mutate(totalSampleSize = R1.fastq.gz + R1.fastq.gz) %>%
  slice_sample(n = nrow(.)) -> sizes # show in random order of rows
```


```{r low cov samples, fig.cap="Distribution of file sizes (combined paired FASTQ files). The red dashed line indicates the 100MB cutoff to filter out samples."}
cutoff_filesize <- 1e8
# same with ggplot
sizes %>%
  ggplot(aes(x = log10(totalSampleSize))) +
  geom_histogram(bins = 100, fill = "skyblue", color = "black") +
  labs(
    x = "log10(File size)",
    y = "Number of samples",
  ) +
  scale_x_continuous(
    breaks = 1:11,
    labels = c("10 B", "100 B", "1 KB", "10 KB", "100 KB", "1 MB", "10 MB", "100 MB", "1 GB", "10 GB", "100 GB"),
    limits = c(0, 11)
  ) +
  geom_vline(xintercept = log10(cutoff_filesize), linetype = "dashed", color = "red")
```

No outliers.

# Mapping QC

```{r mapping qc, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Distribution of mapped reads percentages. The red dashed line indicates the 75% cutoff to filter out samples."}
cutoff <- 75

map_roi_sec_alig <- read_tsv(paste0(dir, "/../results/stats/mapped_to_roi_secondary_alignments.tsv"),
  show_col_types = FALSE
)

read_tsv(paste0(dir, "/../results/stats/multiqc_general_stats.txt"),
  show_col_types = FALSE
) %>%
  left_join(map_roi_sec_alig, by = "Sample") %>%
  mutate(percentage_aligned_on_target = `Mapped_to_ROI(%)`) %>%
  {
    . ->> qc
  } %>%
  select(Sample, `QualiMap_mqc-generalstats-qualimap-percentage_aligned`, percentage_aligned_on_target) %>%
  pivot_longer(cols = -Sample) %>%
  ggplot(aes(x = value)) +
  geom_histogram(bins = 50, fill = "lightblue", color = "black") +
  xlim(0, 101) +
  geom_vline(xintercept = cutoff, linetype = "dashed", color = "red") +
  facet_wrap(~name, scales = "free") +
  labs(
    x = "Percentage of reads",
    y = "Number of samples",
  )
```

```{r}
# filter samples above cutoff
qc %>%
  filter(`QualiMap_mqc-generalstats-qualimap-percentage_aligned` > cutoff & percentage_aligned_on_target > cutoff) %>%
  pull(Sample) %>%
  {
    . ->> high_mapped_samples
  } %>%
  write.table(paste0(dir, "/../results/stats/high_mapped_samples.tsv"),
    quote = FALSE, row.names = FALSE, col.names = FALSE
  )

# print number of remaining samples out of total number
high_mapped_samples %>%
  length() %>%
  paste("out of", qc %>% nrow(), "samples remain after filtering out samples with low mapping quality.")
```

# Coverage per gene per sample

```{r, fig.cap="Distribution of mean read depth per sample. Red dashed line indicates the cutoff value to filter out low coverage samples. Blue line indicates the mean value"}
read_tsv(
  paste(dir, "/../results/stats/gene_coverages_all_samples.tsv",
    sep = ""
  ),
  show_col_types = FALSE
) %>%
  filter(
    !grepl("Antitarget", gene),
    !grepl("chr[x0-9]*:", gene)
  ) -> coverage

# plot mean read depth per sample. Columns are samples

coverage[, c("gene", high_mapped_samples)] -> coverage

covs <- as.matrix(sapply(coverage[, -1], as.numeric))
row.names(covs) <- coverage$gene

cutoff_rd <- 100

covs %>%
  t() %>%
  as_tibble(rownames = "sample") %>%
  # calculate mean read depth per sample for all genes, so all columns except sample
  mutate(mean_rd = rowMeans(.[-1])) %>%
  {
    . ->> cov_w_mean
  } %>%
  select(mean_rd) %>%
  ggplot(aes(x = log10(mean_rd))) +
  geom_histogram(bins = 50, fill = "skyblue", color = "black", alpha = 0.8) +
  labs(
    x = "Mean read depth in log10 scale",
    y = "Number of samples",
  ) +
  geom_vline(xintercept = log10(cutoff_rd), linetype = "dashed", color = "red") +
  # line at mean
  geom_vline(xintercept = log10(mean(cov_w_mean$mean_rd)), linetype = "dashed", color = "blue")

cov_w_mean %>%
  filter(mean_rd > cutoff_rd) %>%
  pull(sample) %>%
  {
    . ->> samples_high_mapp_high_rd
  } %>%
  write.table(
    paste(dir, "/../results/stats/samples_high_mapp_high_rd.tsv", sep = ""),
    quote = FALSE,
    row.names = FALSE,
    col.names = FALSE
  )

# Print the number of discarded samples out of the total number of samples
cat(length(cov_w_mean$mean_rd) - length(samples_high_mapp_high_rd), " samples have a mean read depth below ", cutoff_rd, ".\n", length(samples_high_mapp_high_rd), " samples remain to be analyzed.\n", sep = "")
```

Low coverage samples are filtered out from here on.

```{r cov, message=FALSE,warning=FALSE, fig.width=16, fig.height=8, layout="l-screen-inset", fig.retina = 2, fig.cap="Rows are samples, columns are genes. Read depth is log10-transformed, i.e., the value of 3 means a read depth of 1000."}
# filter covs for samples_high_mapp_high_rd.tsv
covs <- covs[, samples_high_mapp_high_rd]

heatmap.2(log10(t(covs) + 1),
  trace = "none",
  col = colorRampPalette(brewer.pal(9, "YlGnBu"))(100),
  scale = "none",
  cexRow = 0.4,
  cexCol = 0.4,
  margins = c(3, 5)
)
```

```{r boxplots_read_depth, message=FALSE,warning=FALSE, fig.width=16, fig.height=8, layout="l-screen-inset", fig.retina = 2, fig.cap="Read depth distribution per gene."}
covs_df <- as.data.frame(covs)
covs_df$gene <- row.names(covs)
covs_df %>%
  pivot_longer(
    cols = -gene,
    names_to = "sample",
    values_to = "read_depth"
  ) %>%
  group_by(gene) %>%
  mutate(median = median(read_depth)) -> covs_long

ggplot(covs_long, aes(x = gene, y = read_depth, fill = as.factor(median))) +
  geom_boxplot(
    outlier.size = 0.8,
    outlier.fill = "grey",
    outlier.colour = "grey"
  ) +
  labs(x = "Gene", y = "Read Depth") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8)) +
  ylim(0, 6000) +
  scale_fill_manual(values = colorRampPalette(brewer.pal(9, "RdYlBu"))(length(unique(covs_long$median)))) +
  guides(fill = "none")
```

```{r, fig.cap="Histogram of median number of reads per gene."}
medians <- apply(coverage[, -1], 1, median)
ggplot() +
  geom_histogram(aes(x = medians), bins = 40, fill = "skyblue", color = "black") +
  labs(x = "Medians", y = "Frequency") +
  scale_x_continuous(n.breaks = 20) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


## Which genes are outliers?

Outliers when using 10% trimmed mean of gene coverage:

```{r mean}
mn1 <- apply(covs, 1, mean, trim = 0.1)
tab_mn1 <- t(t(boxplot.stats(mn1)$out))
colnames(tab_mn1) <- "10% trimmed mean"

print(round(tab_mn1, 1))
```

Outliers when using median of gene coverage:

```{r median}
md <- apply(covs, 1, median)
tab_md <- t(t(boxplot.stats(md)$out))
colnames(tab_md) <- "median"

print(round(tab_md, 1))
```

## CNV heatmaps by CNVkit

They look a bit ugly because they are not supposed to be used with that many samples. Randomly sampling less samples and plotting these might be a good alternative.
Are some regions always falsely called as gain/loss by CNVkit?

### CBS

![CNV heatmap for CBS](heatmap_compressed_cbs.cnv.png)

### HMM

![CNV heatmap for HMM](heatmap_compressed_hmm.cnv.png)





# Do we see the typical increase in rate of C.G\>T.A transitions in the samples?

Are the samples FFPE or fresh-frozen?

Which transitions are overrepresented or have a high variance among samples?

```{r load snv, message=FALSE, warning=FALSE}
snv <- read_tsv(paste(dir, "/../results/stats/mutect2_snv_counts.tsv", sep = ""),
  show_col_types = FALSE
)
snv %>%
  mutate("mutation" = paste(ref, ">", alt, sep = "")) %>%
  select(-c(ref, alt)) %>%
  # filter out samples with very low coverage
  filter(sample %in% samples_high_mapp_high_rd) %>%
  group_by(sample) %>%
  pivot_wider(names_from = mutation, values_from = count) -> counts

# normalize counts per sample
counts %>%
  pivot_longer(cols = -sample) %>%
  group_by(sample) %>%
  mutate(value = value / sum(value)) %>%
  ungroup() %>%
  pivot_wider(names_from = name, values_from = value) %>%
  mutate(
    transition_perc = (`C>T` + `G>A` + `T>C` + `A>G`) / (`C>T` + `G>A` + `C>G` + `C>A` + `G>C` + `G>T` + `T>G` + `T>A` + `A>C` + `A>T` + `T>C` + `A>G`),
    CT_and_GA_ti_perc = (`C>T` + `G>A`) / transition_perc
  ) -> norm

# check whether normalization worked correctly, total must be =1
# norm %>%
#   pivot_longer(cols = -sample) %>%
#   group_by(sample) %>%
#  mutate(total = sum(value))

# norm %>% summary()
```

```{r, fig.cap="Distribution of SNV counts per sample"}
norm %>%
  select(-transition_perc, -CT_and_GA_ti_perc) %>%
  pivot_longer(cols = -sample) %>%
  ggplot(aes(x = name, y = value * 100)) +
  geom_violin(
    alpha = 0.8,
    aes(fill = name, color = name),
    trim = FALSE
  ) +
  geom_boxplot(width = 0.2) +
  labs(
    x = "",
    y = "percentage of total SNVs",
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Transitions vs transversions

```{r ts vs tv}
# calc. transition/transversion ratio
norm %>%
  pivot_longer(cols = -sample) %>%
  mutate(
    name = factor(name),
    type = ifelse(name %in% c("C>T", "G>A", "T>C", "A>G"), "transition", "transversion"),
  ) %>%
  group_by(sample, type) %>%
  summarise(value = sum(value)) -> transv

# plot only transitions in violin plot
p1 <- norm %>%
  ggplot(aes(x = "", y = transition_perc * 100)) +
  geom_violin(
    alpha = 0.8,
    trim = FALSE,
    color = "skyblue",
    fill = "skyblue"
  ) +
  geom_boxplot(width = 0.2) +
  labs(
    x = "",
    y = "percentage of total SNVs",
    title = "Relative proportion of Ti and Tv"
  ) +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_y_continuous(sec.axis = sec_axis(~ . / (100 - .), name = "Ti/Tv ratio"))

# around 40%, ~= 39% in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4912568/ but probably depends on sample age

p2 <- norm %>%
  ggplot(aes(x = "", y = CT_and_GA_ti_perc * 100)) +
  geom_violin(
    alpha = 0.8,
    trim = FALSE,
    color = "skyblue",
    fill = "skyblue"
  ) +
  geom_boxplot(width = 0.2) +
  labs(
    x = "",
    y = "percentage of total transitions",
    title = "Relative proportion of C.G>T.A Ti to inverse Ti"
  ) +
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  scale_y_continuous(sec.axis = sec_axis(~ . / (100 - .), name = "C.G>T.A to T.A>C.G ratio ratio", breaks = c(1:5, 10, 20)))

# combine plots
ggarrange(p1, p2)
```


# Number of variants passing filter

```{r filter, message=FALSE, warning=FALSE, fig.cap="Distribution of variants and confident classifications as germline or somatic"}
# read in and calc. percentage of variants passing filters
read_tsv(paste(dir, "/../results/stats/mutect2_vcf_filtered_variants_counts.tsv", sep = "")) %>%
  filter(SampleName %in% samples_high_mapp_high_rd) %>%
  mutate(
    PassedVariants_perc = 100 * PassedVariants / TotalVariants,
    GermlineVariants_perc = 100 * GermlineVariants / TotalVariants
  ) -> variant_counts

variant_counts %>%
  select(SampleName, TotalVariants, PassedVariants, GermlineVariants) %>%
  pivot_longer(cols = -SampleName) %>%
  ggplot(aes(x = value)) +
  geom_histogram(alpha = 0.8, bins = 25, col = "black", fill = "skyblue") +
  labs(
    y = "number of samples",
  ) +
  facet_wrap(~name, scales = "free_x")

variant_counts %>%
  select(SampleName, PassedVariants_perc, GermlineVariants_perc) %>%
  pivot_longer(cols = -SampleName) %>%
  ggplot(aes(x = value)) +
  geom_histogram(alpha = 0.8, bins = 20, col = "black", fill = "skyblue") +
  labs(
    y = "number of samples",
  ) +
  facet_wrap(~name, scales = "fixed")
```


# PureCN optima

With global optimum we mean the best model found by PureCN (even if it might not exactly be the *global* optimum), which is "the SNV-fit likelihood is the sum of log-likelihood scores of the most likely states for all variants".

Here, we use only the results obtained by CBS segmentation by CNVkit followed by hierarchical clustering (using Ward's criterion) of the segments by PureCN.

## Distribution of ploidy and purity values

```{r pp_dist, warning=FALSE, fig.cap="Distribution of ploidy and purity values for only the global optimum and all local optima"}
read_tsv(
  file = paste(dir, "/../results/stats/cbs_Hclust_ploidy_purity_local_optima.tsv",
    sep = ""
  ),
  show_col_types = FALSE
) %>%
  filter(sample %in% samples_high_mapp_high_rd) -> df

# collect only best models
df %>%
  group_by(sample) %>%
  filter(total.log.likelihood == max(total.log.likelihood)) %>%
  ungroup() -> global_optima

# add column for later merge
global_optima %>%
  select(purity, total.ploidy) %>%
  mutate(type = "global optimum") -> global

df %>%
  select(purity, total.ploidy) %>%
  mutate(type = "all local optima") -> all

# plot ploidy
plt1 <- bind_rows(global, all) %>%
  ggplot(aes(x = total.ploidy, y = type)) +
  geom_violin(
    alpha = 0.8,
    aes(fill = type, color = type),
    trim = FALSE
  ) +
  geom_boxplot(width = 0.2) +
  labs(
    x = "total.ploidy",
    title = "",
    y = ""
  )

# plot purity
plt2 <- global %>%
  bind_rows(all) %>%
  ggplot(aes(x = purity, y = type)) +
  geom_violin(
    alpha = 0.8,
    aes(fill = type, color = type),
    trim = FALSE
  ) +
  geom_boxplot(width = 0.2) +
  labs(
    x = "purity",
    y = "",
    title = ""
  ) +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )

# combine plots
ggarrange(plt1, plt2, common.legend = TRUE, legend = "bottom")
```

## What happens if we choose the model with highest purity...

... among the best 3 models, knowing/assuming that purity should be high? Will ploidy be too high for these models?

```{r pp_dist_high_purity, warning=FALSE, fig.cap="Distribution of ploidy and purity values for\nonly the global optimum or all local optima"}
# choose high purity models
df %>%
  group_by(sample) %>%
  slice_max(total.log.likelihood, n = 3) %>%
  slice_max(purity, n = 1) %>%
  mutate(type = "high purity models") -> high_pur_models

# plot ploidy
plt1 <- bind_rows(global, high_pur_models) %>%
  ggplot(aes(x = total.ploidy, y = type)) +
  geom_violin(
    alpha = 0.8,
    aes(fill = type, color = type),
    trim = FALSE
  ) +
  geom_boxplot(width = 0.2) +
  labs(
    x = "total.ploidy",
    title = "",
    y = ""
  )

# plot purity
plt2 <- bind_rows(global, high_pur_models) %>%
  ggplot(aes(x = purity, y = type)) +
  geom_violin(
    alpha = 0.8,
    aes(fill = type, color = type),
    trim = FALSE
  ) +
  geom_boxplot(width = 0.2) +
  labs(
    x = "purity",
    y = "",
    title = ""
  )

# combine plots
ggarrange(plt1, plt2, common.legend = TRUE, legend = "bottom")
```

## Decrease in log-likelihood with lower ranking models

How much does the log-likelihood value decrease from the global optimum to other local optima?

```{r llv_decrease, warning=FALSE, fig.cap="Relative log-likelihood value (LLV) decrease"}
# calc. diff. between 1st and 2nd model
df %>%
  group_by(sample) %>%
  slice_max(total.log.likelihood, n = 2) %>%
  mutate(log_likelihood_diff = abs(100 * (total.log.likelihood - lag(total.log.likelihood))
    / total.log.likelihood)) %>%
  ungroup() %>%
  select(log_likelihood_diff) %>%
  filter(!is.na(log_likelihood_diff)) -> best_1_to_2_perc

# idem with 1st and 3rd model
df %>%
  group_by(sample) %>%
  slice_max(total.log.likelihood, n = 3) %>%
  mutate(log_likelihood_diff = abs(100 * (total.log.likelihood - lag(total.log.likelihood, n = 2L))
    / total.log.likelihood)) %>%
  ungroup() %>%
  select(log_likelihood_diff) %>%
  filter(!is.na(log_likelihood_diff)) -> best_1_to_3_perc

# idem 4th model
df %>%
  group_by(sample) %>%
  slice_max(total.log.likelihood, n = 4) %>%
  mutate(log_likelihood_diff = abs(100 * (total.log.likelihood - lag(total.log.likelihood, n = 3L))
    / total.log.likelihood)) %>%
  ungroup() %>%
  select(log_likelihood_diff) %>%
  filter(!is.na(log_likelihood_diff)) -> best_1_to_4_perc

# add column for later merge
best_1_to_2_perc %>%
  mutate(type = "decrease from best to\n2nd best model") -> b12

best_1_to_4_perc %>%
  mutate(type = "decrease from best to\n4th best model") -> b14

# merge and plot
best_1_to_3_perc %>%
  mutate(type = "decrease from best to\n3rd best model") %>%
  bind_rows(b12, b14) %>%
  ggplot(aes(x = log_likelihood_diff, y = type)) +
  geom_violin(
    alpha = 0.8,
    aes(fill = type, color = type),
    trim = FALSE, show.legend = FALSE
  ) +
  geom_boxplot(width = 0.1) +
  labs(
    subtitle = expression(100 * (LLV[best ~ model] - LLV[alternative ~ model]) / LLV[best ~ model]),
    x = "Decrease of log-likelihood in %",
    y = ""
  )
```

The same with (non-log) likelihood values ($e^{LLV}$) makes less sense because the values become very small (<1e-250) and thus hard to interpret.


```{r decrease, warning=FALSE, layout="l-body-outset"}
# calc. statistics
best_1_to_2_perc %>%
  summarise(
    mean = mean(log_likelihood_diff),
    median = median(log_likelihood_diff),
    sd = sd(log_likelihood_diff),
    variance = var(log_likelihood_diff),
    min = min(log_likelihood_diff),
    max = max(log_likelihood_diff)
  ) -> stats2

best_1_to_3_perc %>%
  summarise(
    mean = mean(log_likelihood_diff),
    median = median(log_likelihood_diff),
    sd = sd(log_likelihood_diff),
    variance = var(log_likelihood_diff),
    min = min(log_likelihood_diff),
    max = max(log_likelihood_diff)
  ) -> stats3

best_1_to_4_perc %>%
  summarise(
    mean = mean(log_likelihood_diff),
    median = median(log_likelihood_diff),
    sd = sd(log_likelihood_diff),
    variance = var(log_likelihood_diff),
    min = min(log_likelihood_diff),
    max = max(log_likelihood_diff)
  ) -> stats4

stats <- round(rbind(stats2, stats3, stats4), 1)
row.names(stats) <- c(
  "decrease from best to second best model",
  "decrease from best to third best model",
  "decrease from best to fourth best model"
)

# display statistics as table
stats %>% paged_table()
```


# Are there samples with low ploidy and high purity?

Note: PureCN's total ploidy (total.ploidy or D) includes the normal contamination. Instead, we use tumor ploidy here.


```{r, fig.cap="Purity vs ploidy. The blue line isolates the 10 samples with highest purity, the orange line the 10 samples with lowest purity, and the green line the 10 samples with lowest ploidy."}
global_optima %>%
  group_by(sample) %>%
  mutate(pp_score = purity / ploidy^2) %>%
  filter(sample %in% samples_high_mapp_high_rd) -> optima_scored

pon_size <- 10

optima_scored %>%
  ggplot(aes(x = purity, y = ploidy)) +
  geom_point() +
  labs(x = "Purity", y = "Ploidy") +
  geom_vline(
    xintercept = as.numeric(optima_scored[order(optima_scored$purity, decreasing = TRUE), ][pon_size, "purity"]),
    color = "blue"
  ) +
  geom_hline(
    yintercept = as.numeric(optima_scored[order(optima_scored$ploidy, decreasing = FALSE), ][pon_size, "ploidy"]),
    color = "green"
  ) +
  geom_vline(
    xintercept = as.numeric(optima_scored[order(optima_scored$purity, decreasing = FALSE), ][pon_size, "purity"]),
    color = "orange"
  )
```

```{r save 50 samples, eval=TRUE, include=FALSE}
write_tsv(optima_scored[order(optima_scored$purity, decreasing = TRUE), ][1:pon_size, "sample"],
  paste(dir, "/../results/stats/highpurity_samples.tsv", sep = ""),
  col_names = FALSE
)
write_tsv(optima_scored[order(optima_scored$purity, decreasing = FALSE), ][1:pon_size, "sample"],
  paste(dir, "/../results/stats/lowpurity_samples.tsv", sep = ""),
  col_names = FALSE
)
write_tsv(optima_scored[order(optima_scored$ploidy, decreasing = FALSE), ][1:pon_size, "sample"],
  paste(dir, "/../results/stats/lowploidy_samples.tsv", sep = ""),
  col_names = FALSE
)


# quick check

# does lowploidy_samples.tsv contain samples not in samples_high_mapp_high_rd.tsv?
lowploidy <- read_tsv(paste(dir, "/../results/stats/lowploidy_samples.tsv", sep = ""), col_names = FALSE)
high_mapped <- read_tsv(paste(dir, "/../results/stats/samples_high_mapp_high_rd.tsv", sep = ""), col_names = FALSE)

lowploidy %>%
  filter(!X1 %in% high_mapped$X1)

lowploidy %>%
  filter(!X1 %in% samples_high_mapp_high_rd)
```

# Compare found purity values with the ones estimated by the pathologists

```{r, fig.cap="Comparison of purity values estimated by PureCN and the pathologists"}
excel_file <- paste0(dir, "/../resources/data/s_panel_pathology.xlsx")

# check whether file exists
if (!file.exists(excel_file)) {
  cat("The file ", excel_file, " does not exist. Purity estimation comparison will be skipped.\n")
} else {
  readxl::read_excel(excel_file, skip = 1) %>%
    select(Name...1, `Tumor Purity`) %>%
    mutate(
      Name...1 = ifelse(grepl("[A-Z]0+[0-9]+", Name...1), sub("0+", "", Name...1, ), Name...1)
    ) -> truth

  global_optima %>%
    select(sample, purity) %>%
    mutate(
      sample = str_remove(sample, "_.*") %>%
        str_replace("-", "_"),
      sample = ifelse(grepl("[A-Z]0+[0-9]+", sample), sub("0+", "", sample, ), sample)
    ) %>%
    left_join(truth, by = c("sample" = "Name...1")) %>%
    rename(
      "purity_purecn" = purity,
      "purity_pathologists" = `Tumor Purity`
    ) %>%
    filter(!is.na(purity_pathologists)) %>%
    mutate(
      purity_purecn = 100 * purity_purecn,
      purity_pathologists = as.numeric(purity_pathologists)
    ) -> purity_comparison

  cat("Out of the", nrow(global_optima), "analysed samples, there are", nrow(purity_comparison), "samples\nwith purity values estimated by both PureCN and the pathologists.\n")

  cat("Out of the", nrow(purity_comparison), "samples, the pathologists estimated\nthe purity of", sum(purity_comparison$purity_purecn < purity_comparison$purity_pathologists), "samples to be strictly higher than PureCN did.\n")

  # average difference between pathologists' and PureCN's purity values
  cat("The average difference between the pathologists' and PureCN's purity values is", round(mean(purity_comparison$purity_purecn - purity_comparison$purity_pathologists), 1), ".\n")

  # plot pathologists' vs PureCN's purity values
  purity_comparison %>%
    ggplot(aes(x = purity_pathologists, y = purity_purecn)) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1, color = "red") +
    labs(x = "Pathologists' purity estimation", y = "PureCN's purity estimation") +
    scale_x_continuous(breaks = seq(0, 100, 10), limits = c(0, 100)) +
    scale_y_continuous(breaks = seq(0, 100, 10), limits = c(0, 100)) +
    geom_smooth(method = "lm", se = FALSE)
}
```

```{r, fig.cap="Histogram of differences in purity estimation (PureCN - pathologists)"}
# check whether file exists
if (!file.exists(excel_file)) {
  cat("The file ", excel_file, " does not exist. Purity estimation comparison will be skipped.\n")
} else {
  # compare differences between pathologists' and PureCN's purity values
  purity_comparison %>%
    mutate(difference = purity_purecn - purity_pathologists) %>%
    ggplot(aes(x = difference)) +
    geom_histogram(bins = 21, fill = "skyblue", color = "black") +
    labs(x = "Difference in purity estimation compared to the pathologists' estimation", y = "Number of samples") +
    scale_x_continuous(breaks = seq(-100, 100, 10), limits = c(-100, 100))
}
```











